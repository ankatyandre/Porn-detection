{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = train_df.iloc[1 : int(len(train_df)/2)]\n",
    "X_2 = train_df.iloc[int(len(train_df)/2) + 1 : int(3*len(train_df)/4)]\n",
    "X_3 = train_df.iloc[int(3*len(train_df)/4) + 1 : ]\n",
    "\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = X_1['target']\n",
    "y_2 = X_2['target']\n",
    "y_3 = X_3['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_1[['url', 'title']]\n",
    "X_2 = X_2[['url', 'title']]\n",
    "X_3 = X_3[['url', 'title']]\n",
    "\n",
    "X_test = X_test[['url', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combine(df):\n",
    "      return pd.Series([(\"xxx\"  in text.lower()) or(\"gay\"  in text.lower()) or(\"blowjob\"  in text.lower()) or(\"bobs\"  in text.lower()) or(\"hentai\"  in text.lower()) or(\"squirt\"  in text.lower()) or(\"pussy\"  in text.lower()) or(\"fuck\"  in text.lower()) or(\"cum\"  in text.lower()) or(\"porn\"  in text) or(\"sex\"  in text) or(\"tits\"  in text)or(\"girl\"  in text)  for text in df['url']])\\\n",
    "          |  pd.Series([(\"ебля\"  in text.lower()) or(\"ебут\"  in text.lower()) or(\"biqle\"  in text.lower()) or\\\n",
    "                  (\"дроч\"  in text.lower()) or(\"пизда\"  in text.lower()) or(\"письк\"  in text.lower()) or\\\n",
    "                  (\"мастурбирует\"  in text.lower()) or(\"xxx\"  in text.lower()) or(\"оттрахали\"  in text.lower()) or\\\n",
    "                  (\"оттрахали\"  in text.lower()) or(\"отымели\"  in text.lower()) or(\"gay\"  in text.lower()) or\\\n",
    "                  (\"dick\"  in text.lower()) or (\"шлюх\"  in text.lower()) or(\"naked\"  in text.lower()) or\\\n",
    "                  (\"эроти\"  in text.lower()) or(\"blowjob\"  in text.lower()) or(\"bobs\"  in text.lower()) or\\\n",
    "                  (\"порн\"  in text.lower()) or (\"hentai\"  in text.lower()) or(\"оргия\"  in text.lower()) or\\\n",
    "                  (\"orgy\"  in text.lower()) or(\"cock\"  in text.lower()) or(\"orgasm\"  in text.lower()) or\\\n",
    "                  (\"squirt\"  in text.lower()) or(\"pussy\"  in text.lower()) or(\"fuck\"  in text.lower()) or\\\n",
    "                  (\"cum\"  in text.lower()) or(\"пенис\"  in text.lower()) or(\"сиськ\"  in text.lower()) or\\\n",
    "                  ((\"трах\"  in text.lower()) and not (\"cтрах\" not in text.lower()))  or(\"сперм\"  in text.lower()) or\\\n",
    "                  (\"минет\"  in text.lower()) or(\"xxx\"  in text.lower()) or (\"жоп\"  in text.lower()) or \\\n",
    "                  (\"трахают\"  in text.lower()) or (\"титьк\"  in text.lower()) or (\"индивидуалка\"  in text.lower()) or\\\n",
    "                  (\"член\"  in text.lower()) or(\"хентай\"  in text.lower()) or(\"шлюха\"  in text.lower()) or\\\n",
    "                  (\"проститутка\"  in text.lower()) or(\"секс\"  in text.lower()) or(\"в рот\"  in text.lower())  or\\\n",
    "                  (\"сосет\"  in text.lower()) or(\"сосет\"  in text.lower()) or(\"ебет\"  in text.lower()) or\\\n",
    "                  (\"сиськи\"  in text.lower()) or(\"porn\"  in text.lower()) or(\"sex\"  in text.lower()) or\\\n",
    "                  (\"tits\"  in text.lower())or(\"girl\"  in text.lower())or(\"girl\"  in text.lower())\\\n",
    "                  for text in df['title']])\\\n",
    "          .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_combine = make_combine(X_1)\n",
    "X2_combine = make_combine(X_2)\n",
    "X3_combine = make_combine(X_3)\n",
    "Xtest_combine = make_combine(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url(df):\n",
    "      return pd.Series([(\"xxx\"  in text.lower()) or(\"gay\"  in text.lower()) or(\"blowjob\"  in text.lower()) or(\"bobs\"  in text.lower()) or(\"hentai\"  in text.lower()) or(\"squirt\"  in text.lower()) or(\"pussy\"  in text.lower()) or(\"fuck\"  in text.lower()) or(\"cum\"  in text.lower()) or(\"porn\"  in text) or(\"sex\"  in text) or(\"tits\"  in text)or(\"girl\"  in text)  for text in df['url']])\\\n",
    "          .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_url_flags = make_url(X_1)\n",
    "X2_url_flags = make_url(X_2)\n",
    "X3_url_flags = make_url(X_3)\n",
    "\n",
    "Xtest_url_flags = make_url(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_title(df):\n",
    "      return pd.Series([(\"ебля\"  in text.lower()) or(\"ебут\"  in text.lower()) or(\"biqle\"  in text.lower()) or\\\n",
    "                  (\"дроч\"  in text.lower()) or(\"пизда\"  in text.lower()) or(\"письк\"  in text.lower()) or\\\n",
    "                  (\"мастурбирует\"  in text.lower()) or(\"xxx\"  in text.lower()) or(\"оттрахали\"  in text.lower()) or\\\n",
    "                  (\"оттрахали\"  in text.lower()) or(\"отымели\"  in text.lower()) or(\"gay\"  in text.lower()) or\\\n",
    "                  (\"dick\"  in text.lower()) or (\"шлюх\"  in text.lower()) or(\"naked\"  in text.lower()) or\\\n",
    "                  (\"эроти\"  in text.lower()) or(\"blowjob\"  in text.lower()) or(\"bobs\"  in text.lower()) or\\\n",
    "                  (\"порн\"  in text.lower()) or (\"hentai\"  in text.lower()) or(\"оргия\"  in text.lower()) or\\\n",
    "                  (\"orgy\"  in text.lower()) or(\"cock\"  in text.lower()) or(\"orgasm\"  in text.lower()) or\\\n",
    "                  (\"squirt\"  in text.lower()) or(\"pussy\"  in text.lower()) or(\"fuck\"  in text.lower()) or\\\n",
    "                  (\"cum\"  in text.lower()) or(\"пенис\"  in text.lower()) or(\"сиськ\"  in text.lower()) or\\\n",
    "                  ((\"трах\"  in text.lower()) and not (\"cтрах\" not in text.lower()))  or(\"сперм\"  in text.lower()) or\\\n",
    "                  (\"минет\"  in text.lower()) or(\"xxx\"  in text.lower()) or (\"жоп\"  in text.lower()) or \\\n",
    "                  (\"трахают\"  in text.lower()) or (\"титьк\"  in text.lower()) or (\"индивидуалка\"  in text.lower()) or\\\n",
    "                  (\"член\"  in text.lower()) or(\"хентай\"  in text.lower()) or(\"шлюха\"  in text.lower()) or\\\n",
    "                  (\"проститутка\"  in text.lower()) or(\"секс\"  in text.lower()) or(\"в рот\"  in text.lower())  or\\\n",
    "                  (\"сосет\"  in text.lower()) or(\"сосет\"  in text.lower()) or(\"ебет\"  in text.lower()) or\\\n",
    "                  (\"сиськи\"  in text.lower()) or(\"porn\"  in text.lower()) or(\"sex\"  in text.lower()) or\\\n",
    "                  (\"tits\"  in text.lower())or(\"girl\"  in text.lower())or(\"girl\"  in text.lower())\\\n",
    "                  for text in df['title']])\\\n",
    "          .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_title_flags = make_title(X_1)\n",
    "X2_title_flags = make_title(X_2)\n",
    "X3_title_flags = make_title(X_3)\n",
    "\n",
    "Xtest_title_flags = make_title(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big datasets X_2 X_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_new = pd.DataFrame()\n",
    "X_3_new = pd.DataFrame()\n",
    "\n",
    "X_test_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer + SVD + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_1_vect = vectorizer.fit_transform(X_1['title'])\n",
    "X_2_vect = vectorizer.transform(X_2['title'])\n",
    "X_3_vect = vectorizer.transform(X_3['title'])\n",
    "X_test_vect = vectorizer.transform(X_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svd = TruncatedSVD(n_components=1000)\n",
    "X1_svd = svd.fit_transform(X_1_vect)\n",
    "X2_svd = svd.transform(X_2_vect)\n",
    "X3_svd = svd.transform(X_3_vect)\n",
    "Xtest_svd = svd.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X1_svd_df = pd.DataFrame(X1_svd)\n",
    "X2_svd_df = pd.DataFrame(X2_svd)\n",
    "X3_svd_df = pd.DataFrame(X3_svd)\n",
    "Xtest_svd_df = pd.DataFrame(Xtest_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_svd_df['combine'] = X1_combine.astype(int)\n",
    "X2_svd_df['combine'] = X2_combine.astype(int)\n",
    "X3_svd_df['combine'] = X3_combine.astype(int)\n",
    "Xtest_svd_df['combine'] = Xtest_combine.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_svd_df_not_combine = X1_svd_df.drop('combine', axis = 1)\n",
    "X2_svd_df_not_combine = X2_svd_df.drop('combine', axis = 1)\n",
    "X3_svd_df_not_combine = X3_svd_df.drop('combine', axis = 1)\n",
    "\n",
    "Xtest_svd_df_not_combine =  Xtest_svd_df.drop('combine', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_svd_df_url = X1_svd_df.drop('combine', axis = 1)\n",
    "X2_svd_df_url = X2_svd_df.drop('combine', axis = 1)\n",
    "X3_svd_df_url = X3_svd_df.drop('combine', axis = 1)\n",
    "Xtest_svd_df_url =  Xtest_svd_df.drop('combine', axis = 1)\n",
    "\n",
    "X1_svd_df_url['url_flags'] = X1_url_flags\n",
    "X2_svd_df_url['url_flags'] = X2_url_flags\n",
    "X3_svd_df_url['url_flags'] = X3_url_flags\n",
    "Xtest_svd_df_url['url_flags'] = Xtest_url_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_svd_df_title = X1_svd_df.drop('combine', axis = 1)\n",
    "X2_svd_df_title = X2_svd_df.drop('combine', axis = 1)\n",
    "X3_svd_df_title = X3_svd_df.drop('combine', axis = 1)\n",
    "Xtest_svd_df_title =  Xtest_svd_df.drop('combine', axis = 1)\n",
    "\n",
    "X1_svd_df_title['title_flags'] = X1_title_flags\n",
    "X2_svd_df_title['title_flags'] = X2_title_flags\n",
    "X3_svd_df_title['title_flags'] = X3_title_flags\n",
    "Xtest_svd_df_title['title_flags'] = Xtest_title_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_svd_df_title_url = X1_svd_df.drop('combine', axis = 1)\n",
    "X2_svd_df_title_url = X2_svd_df.drop('combine', axis = 1)\n",
    "X3_svd_df_title_url = X3_svd_df.drop('combine', axis = 1)\n",
    "Xtest_svd_df_title_url =  Xtest_svd_df.drop('combine', axis = 1)\n",
    "\n",
    "X1_svd_df_title_url['url_flags'] = X1_url_flags\n",
    "X2_svd_df_title_url['url_flags'] = X2_url_flags\n",
    "X3_svd_df_title_url['url_flags'] = X3_url_flags\n",
    "Xtest_svd_df_title_url['url_flags'] = Xtest_url_flags\n",
    "\n",
    "X1_svd_df_title_url['title_flags'] = X1_title_flags\n",
    "X2_svd_df_title_url['title_flags'] = X2_title_flags\n",
    "X3_svd_df_title_url['title_flags'] = X3_title_flags\n",
    "Xtest_svd_df_title_url['title_flags'] = Xtest_title_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(model, X_1_train, y_1, X_2_train, y_2, X_3_train, y_3):\n",
    "    model.fit(X_1_train, y_1.astype(int))\n",
    "        \n",
    "    y_2_pred  = model.predict(X_2_train)\n",
    "    print(\"ON X_2 SCORE IS: \", f1_score(y_2, y_2_pred))\n",
    "\n",
    "    y_3_pred  = model.predict(X_3_train)\n",
    "    print(\"ON X_3 SCORE IS: \", f1_score(y_3, y_3_pred))\n",
    "    \n",
    "    return y_2_pred, y_3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_proba(model, X_1_train, y_1, X_2_train, y_2, X_3_train, y_3):\n",
    "    y_2_pred  = model.predict_proba(X_2_train)[:,1]\n",
    "    y_3_pred  = model.predict_proba(X_3_train)[:,1]\n",
    "    \n",
    "    return y_2_pred, y_3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON X_2 SCORE IS:  0.9649805447470816\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "X_2_new['lr_combine_10'], X_3_new['lr_combine_10'], X_test_new['lr_combine_10'] = make_pred(lr, X1_svd_df, y_1, X2_svd_df, y_2, X3_svd_df, y_3, Xtest_svd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_2_new['lr_combine_pred_proba_10'], X_3_new['lr_combine_pred_proba_10'], X_test_new['lr_combine_pred_proba_10'] = make_pred_proba(lr, X1_svd_df, y_1, X2_svd_df, y_2, X3_svd_df, y_3, Xtest_svd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "X_2_new['lr_url_10'], X_3_new['lr_url_10'], X_test_new['lr_url_10'] = make_pred(lr, X1_svd_df_url, y_1, X2_svd_df_url, y_2, X3_svd_df_url, y_3, Xtest_svd_df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_2_new['lr_url_pred_proba_10'], X_3_new['lr_url_pred_proba_10'], X_test_new['lr_url_pred_proba_10'] = make_pred_proba(lr, X1_svd_df_url, y_1, X2_svd_df_url, y_2, X3_svd_df_url, y_3, Xtest_svd_df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "X_2_new['lr_title_10'], X_3_new['lr_url_10'], X_test_new['lr_url_10'] = make_pred(lr, X1_svd_df_url, y_1, X2_svd_df_url, y_2, X3_svd_df_url, y_3, Xtest_svd_df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X1_svd_df, y_1.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964277035236938"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2_pred = lr.predict(X2_svd_df)\n",
    "X_2_new['logreg'] = y_2_pred\n",
    "f1_score(y_2, y_2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639477781770271"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3_pred = lr.predict(X3_svd_df)\n",
    "X_3_new['logreg'] = y_3_pred\n",
    "f1_score(y_3, y_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_new['logreg_pr']  = lr.predict_proba(X2_svd_df)[:,1]\n",
    "X_3_new['logreg_pr']  = lr.predict_proba(X3_svd_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr2 = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X1_svd_df_not_combine, y_1.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272244019744337"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2_pred_lr_no_combine = lr2.predict(X2_svd_df_not_combine)\n",
    "X_2_new['logreg_no_combine'] = y_2_pred_lr_no_combine\n",
    "f1_score(y_2, y_2_pred_lr_no_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9293030227329502"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3_pred_lr_no_combine = lr2.predict(X3_svd_df_not_combine)\n",
    "X_3_new['logreg_no_combine'] = y_3_pred_lr_no_combine\n",
    "f1_score(y_3, y_3_pred_lr_no_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_new['logreg_no_combine_pr']  = lr2.predict_proba(X2_svd_df_not_combine)[:,1]\n",
    "X_3_new['logreg_no_combine_pr']  = lr2.predict_proba(X3_svd_df_not_combine)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer + SVD + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=10)\n",
    "rf1.fit(X1_svd_df, y_1.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9359519639729799"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2_pred_rf1 = rf1.predict(X2_svd_df)\n",
    "X_2_new['rf1'] = y_2_pred_rf1\n",
    "f1_score(y_2, y_2_pred_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374462332554996"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3_pred_rf1 = rf1.predict(X3_svd_df)\n",
    "X_3_new['rf1'] = y_3_pred_rf1\n",
    "f1_score(y_3, y_3_pred_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=10)\n",
    "rf2.fit(X1_svd_df_not_combine, y_1.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871882834146985"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2_pred_rf2 = rf2.predict(X2_svd_df_not_combine)\n",
    "X_2_new['rf2'] = y_2_pred_rf2\n",
    "f1_score(y_2, y_2_pred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875862967304937"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3_pred_rf2 = rf2.predict(X3_svd_df_not_combine)\n",
    "X_3_new['rf2'] = y_3_pred_rf2\n",
    "f1_score(y_3, y_3_pred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=30)\n",
    "rf3.fit(X1_svd_df_not_combine, y_1.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8903732809430257"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2_pred_rf3 = rf3.predict(X2_svd_df_not_combine)\n",
    "X_2_new['rf3'] = y_2_pred_rf3\n",
    "f1_score(y_2, y_2_pred_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943507914039377"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3_pred_rf3 = rf2.predict(X3_svd_df_not_combine)\n",
    "X_3_new['rf3'] = y_3_pred_rf3\n",
    "f1_score(y_3, y_3_pred_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hui(model, X_1_train, y_1, X_2_train, y_2, X_3_train, y_3):\n",
    "    model.fit(X_1_train, y_1.astype(int))\n",
    "        \n",
    "    y_2_pred  = model.predict(X_2_train)\n",
    "    print(\"ON X_2 SCORE IS: \", f1_score(y_2, y_2_pred))\n",
    "\n",
    "    y_3_pred  = model.predict(X_3_train)\n",
    "    print(\"ON X_3 SCORE IS: \", f1_score(y_3, y_3_pred))\n",
    "    \n",
    "    return y_2_pred, y_3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
